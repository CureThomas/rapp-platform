<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>RAPP Platform Wiki: rapp-platform.wiki/RAPP-Speech-Detection-using-Sphinx4.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="RAPP_logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">RAPP Platform Wiki
   &#160;<span id="projectnumber">v0.6.0</span>
   </div>
   <div id="projectbrief">RAPP Platform is a collection of ROS nodes and back-end processes that aim to deliver ready-to-use generic services to robots</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('RAPP-Speech-Detection-using-Sphinx4_8md.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">rapp-platform.wiki/RAPP-Speech-Detection-using-Sphinx4.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="RAPP-Speech-Detection-using-Sphinx4_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;In our <span class="keywordflow">case</span> we desire a flexible speech recognition module, capable of multi-language extension and good performance on limited or generalized language models. For <span class="keyword">this</span> reason, Sphinx-4 was selected. Since we aim <span class="keywordflow">for</span> speech detection services <span class="keywordflow">for</span> RApps regardless of the actual robot at hand, we decided to install Sphinx-4 in the RAPP Cloud and provide services <span class="keywordflow">for</span> uploading or streaming audio, as well as configuring the ASR towards language or vocabulary-specific decisions.</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;Before proceeding to the actual description, it should be said that the RAPP Sphinx4 detection was create in order to handle **limited vocabulary** speech recognition in various languages. This means that it is not suggested <span class="keywordflow">for</span> detecting words in free speech or words from a vocabulary larger than 10-15 words.</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;Before describing the actual implementation, it is necessary to investigate the Sphinx-4 configuration capabilities. In order to perform speech detection, Sphinx-4 requires: </div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;</div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;- An acoustic model containing information about senones. Senones are <span class="keywordtype">short</span> sound detectors able to represent the specific language<span class="stringliteral">&#39;s sound elements (phones, diphones, triphones etc.). In order to train an acoustic model for an unsupported language an abundance of data must be available. CMU Sphinx supports a number of high-quality acoustic models, including US English, German, Russian, Spanish, French, Dutch, Mexican and Mandarin.  In the RAPP case we desire multi speakers support, thus as Sphinx-4 suggests, 50 hours of dictation from 200 different speakers are necessary [ref](http://cmusphinx.sourceforge.net/wiki/tutorialam), including the knowledge of the language&#39;</span>s phonetic structure, as well as enough time to train the model and optimize its parameters. If these resources are unavailable (which is the current <span class="keywordflow">case</span>), a possibility is to utilize the US English acoustic model and perform grapheme to phoneme transformations.</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;- A language model, used to restrict word search. Usually n-gram (an n-character slice of a bigger <span class="keywordtype">string</span>) language models are used in order to strip non probable words during the speech detection procedure, thus minimizing the search time and optimizing the overall procedure. Sphinx-4 supports two language models: grammars and statistical language models. Statistical language models include a set of sentences from which probabilities of words and succession of words are extracted. A grammar is a more <span class="stringliteral">&#39;&#39;</span>strict<span class="stringliteral">&#39;&#39;</span> language model, since the ASR tries to match the input speech only to the provided sentences. In our <span class="keywordflow">case</span>, we are initially interested in detecting single words from a limited vocabulary, thus no special attention was paid in the construction of a generalized Greek language model.</div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;- A phonetic dictionary, which essentially is a mapping from words to phones. This procedure is usually performed <span class="keyword">using</span> G2P converters (Grapheme-to-Phoneme), such as [Phonetisaurus](https:<span class="comment">//code.google.com/p/phonetisaurus/) or [sequitur-g2p3](http://www-i6.informatik.rwth-aachen.de/web/Software/g2p.html). G2P converters are used in almost all TTSs (Text-to-Speech converters), as they require pronunciation rules to work correctly. Here, we decided to not use a G2P tool, but investigate and document the overall G2P procedure of translating Greek graphemes directly into the CMU Arpabet format (which Sphinx supports). </span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;The overall Speech Detection architecture utilizing the Sphinx4 library is presented in the figure below:</div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;[[images/sphinx_diagram.png]]</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;As evident, two distinct parts exist: the NAO robot and RAPP Cloud part. Let’s assume that a robotic application (RApp) is deployed in the robot, which needs to perform speech detection. The first step is to invoke the Capture Audio service the Core agent provides, which in turn captures an audio file via the NAO microphones. This audio file is sent to the cloud RAPP ASR node in order to perform ASR. The most important module of the RAPP ASR is the Sphinx-4 wrapper. This node is responsible for receiving the service call data and configuring the Sphinx-4 software according to the request. The actual Sphinx-4 library is executed as a separate process and Sphinx-4 wrapper is communicating with it via sockets.</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;Between the RAPP ASR and the Sphinx-4 wrapper lies the Sphinx-4 Handler node which is responsible for handling the actual service request. It maintains a number of Sphinx wrappers in different threads, each of which is capable of handling a different request. The Sphinx-4 handler is responsible for scheduling the Sphinx-4 wrapper threads and for this purpose maintains information about the state of each thread (active/idle) and each thread&#39;s previous configuration parameters. Three possible situations exist:</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;1. If a thread is idle and its previous configuration matches the request&#39;s configuration, this thread is selected to handle the request as the time consuming configuration procedure can be skipped.</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;2. If no idle thread&#39;s configuration matches the request&#39;s configuration, an idle thread is chosen at random.</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;3. If all threads are active, the request is put on hold until a thread is available.</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;Regarding the Sphinx-4 configuration, the user is able to select the ASR language and if they desire ASR on a limited vocabulary or on a generalized one stored in the RAPP cloud. If a limited vocabulary is selected, the user can also define the language model (the sentences of the statistical language model or the grammar). The configuration task is performed by the Sphinx-4 Configuration module. There, the ASR language is retrieved and the corresponding language modules are employed (currently Greek, English and their combination). If the user has requested ASR on a limited vocabulary, the corresponding language module must feed the Limited vocabulary creator with the correct grapheme to phoneme transformations, in order to create the necessary configuration files. In the English case, this task is easy, since Sphinx-4 provides a generalized English vocabulary, which includes the words&#39; G2P transformations. When Greek is requested, a simplified G2P method is implemented, which will be discussed next.  In the case where the user requests a generalized ASR, the predefined generalized dictionaries are used (currently only English support exists).</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;The second major task that needs to be performed before the actual Sphinx-4 ASR is the audio preparation. This involves the employment of the **SoX** audio library utilizing the [Audio processing](https:<span class="comment">//github.com/rapp-project/rapp-platform/wiki/RAPP-Audio-Processing) node. Then the audio file is provided to the Sphinx4 Java library and the resulting words are extracted and transmitted back to the RApp, as a response to the HOP service call.</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;Regarding the Greek support, first a description of some basic rules of the Greek language will be presented. The Greek language is equipped with 24 letters and 25 phonemes. Phonemes are structural sound components defining a word’s acoustic properties. Some pronunciation rules the Greek language has follow:</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;- Double letters are two letters that contain two phonemes.</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;- Two digit vowels are two-letter combinations that sound like a single vowel phoneme.</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;- There is a special “s” letter, which is placed at the word’s end instead of the “normal” &#39;s&#39; letter.</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;- The common consonants are two common letter combinations that sound exactly like the single case letter. </div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;- There are some special vowel combinations that are pronounced differently according to what letter is next.</div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;- A grammatical symbol is the acute accent (Greek tonos), denoting where the word is accented.</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;- Another special symbol is diaeresis.</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;- There are some sigma rules, where if sigma is followed by specific letters it sounds like z. </div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;Finally, there are several other trivial and rare rules that we did not take under consideration in our approach.</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;Let’s assume that some Greek words are available and we must configure the Sphinx4 library in order to perform speech recognition. These words must be converted to the Sphinx4-supported Arpabet format which contains 39 phonemes. The individual steps followed are:</div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;- Substitute upper case letters by the corresponding lower case</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;- Substitute two-letter phonemes and common consonants with CMU phonemes</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;- Substitute special vowel combinations</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;- Substitute two digit vowels by CMU phonemes</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;- Substitute special sigma rules</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;- Substitute all remaining letters with CMU phonemes</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;Then, the appropriate files are created (custom dictionary and language model) and the Sphinx4 library is configured. Then the audio pre-processing takes place, performing denoising similarly to the Google Speech Recognition module by deploying the ROS services of the Audio processing node.</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;The RAPP Speech Detection using Sphinx component diagram is depicted in the figure.</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;[[images/sphinx_speech_component_diagram.png]]</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="preprocessor"># ROS Services</span></div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="preprocessor"></span></div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;It should be stated that the language model is created based on the ARPA model <span class="keywordflow">for</span> the ```sentences``` and on the JSGS <span class="keywordflow">for</span> the ```grammar``` parameters, nevertheless only pure sentences are supported (i.e. the advanced JSGF uses cannot be employed). More information on the Sphinx language model can be found [here](http:<span class="comment">//cmusphinx.sourceforge.net/wiki/tutoriallm). </span></div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="preprocessor">## Speech Recognition using Sphinx service</span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="preprocessor"></span>The Sphinx4 ROS node provides a ROS service, dedicated to perform speech recognition.</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;Service URL: ```/rapp/rapp_speech_detection_sphinx4/batch_speech_to_text```</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;Service type:</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;```bash</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="preprocessor">#The language we want ASR for</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span> language</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="preprocessor">#The limited vocabulary. If this is empty a general vocabulary is supposed</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span>[] words</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="preprocessor">#The language model in the form of grammar</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span>[] grammar</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="preprocessor">#The language model in the form of sentences</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span>[] sentences</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="preprocessor">#The audio file path</span></div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span> path</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="preprocessor">#The audio file type</span></div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span> audio_source</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="preprocessor">#The user requesting the ASR</span></div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="preprocessor"></span>String user</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;---</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="preprocessor">#The words recognized</span></div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span>[] words</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="preprocessor">#Possible error</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="preprocessor"></span><span class="keywordtype">string</span> error</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;``` </div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="preprocessor"># Web services</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="preprocessor"></span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="preprocessor">## Speech recognition sphinx RPS</span></div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="preprocessor"></span></div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;The speech_recognition_sphinx RPS is of type 3 since it contains a HOP service frontend, contacting a RAPP ROS node, which utilizes the Sphinx4 library. The speech_recognition_sphinx RPS can be invoked <span class="keyword">using</span> the following URI: </div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;Service URL: ```localhost:9001/hop/speech_recognition_sphinx4```</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="preprocessor">### Input/Output</span></div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="preprocessor"></span>The speech_recognition_sphinx RPS has several input arguments, which are encoded in JSON format in an ASCII <span class="keywordtype">string</span> representation.</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;The speech_detection_sphinx RPS returns the recognized words in JSON forma.</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;```</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;Input = {</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  “language”: “gr, en”</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  “words”: “[WORD_1, WORD_2 …]”</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  “grammar”: “[WORD_1, WORD_2 …]”</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  “sentences”: “[WORD_1, WORD_2 …]”</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;  “file”: “AUDIO_FILE_URI”</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;  “audio_source”: “nao_ogg, nao_wav_1_ch, nao_wav_4_ch, headset”</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;}</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;```</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;```</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;Output = {</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;  “words”: “[WORD_1, WORD_2 …]</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;  “error”: “Possible error”</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;}</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;```</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;The request parameters are:</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;- `language`: The language to perform ASR (Automatic Speech Recognition). Supported values:</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160; - `en`: English</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160; - `el`: Greek (also supports English)</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;- `words[]`: The limited vocabulary from which Sphinx4 will <span class="keywordflow">do</span> the matching. Must provide individual words in the language declared in the language parameter. If left empty a generalized vocabulary will be assumed. This will be valid <span class="keywordflow">for</span> English but the results are not good.</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;- `grammar[]`: A form of language model. Contains either words or sentences that contain the words declared in the words parameter. If grammar is declared, Sphinx4 will either <span class="keywordflow">return</span> results that exist as is in grammar or &lt;nul&gt; <span class="keywordflow">if</span> no matching exists.</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;- `sentences[]`: The second form of language model. Same functionality as grammar but Sphinx can <span class="keywordflow">return</span> individual words contained in the sentences provided. This is essentially used to extract probabilities regarding the phonemes succession.</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;- `file`: The audio file path.</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;- `audio_source`: Declares the source of the audio capture in order to perform correct denoising. The different types are:</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160; - headset: Clean sound, no denoising needed</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160; - nao_ogg: Captured ogg file from a single microphone from NAO. Supposed to have 1 channel.</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160; - nao_wav_1_ch: Captured wav file from one microphone of NAO. Supposed to have 1 channel, 16kHz.</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160; - nao_wav_4_ch: Captured wav file from all 4 NAO<span class="stringliteral">&#39;s microphones. Supposed to have 4 channels at 48kHz.</span></div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="stringliteral">- `user`: The user invoking the service. Must exist as username in the database to work. Also a noise profile for the declared user must exist (check rapp_audio_processing node for set_noise_profile service)</span></div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="stringliteral"></span></div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="stringliteral">The returned parameters are:</span></div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="stringliteral"></span></div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="stringliteral">- `error`: Possible errors</span></div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="stringliteral">- `words[]`: The recognized words</span></div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="stringliteral"></span></div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="stringliteral">The full documentation exists [here](https://github.com/rapp-project/rapp-platform/tree/master/rapp_web_services/services#speech-detection-sphinx4)</span></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="RAPP-Speech-Detection-using-Sphinx4_8md.html">RAPP-Speech-Detection-using-Sphinx4.md</a></li>
    <li class="footer">Generated on Tue Jul 19 2016 11:43:36 for RAPP Platform Wiki by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
