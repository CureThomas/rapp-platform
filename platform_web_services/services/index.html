<!DOCTYPE html>

<html lang="en">
<head>
	<meta charset="utf-8">
	<title>RAPP Platform Web Services Index</title>

	<!--[if lt IE 9]>
	<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->
	<link type="text/css" rel="stylesheet" href="styles/sunlight.default.css">

	<link type="text/css" rel="stylesheet" href="styles/site.cosmo.css">

</head>

<body>

<div class="navbar navbar-default navbar-fixed-top navbar-inverse">
<div class="container">
	<div class="navbar-header">
		<a class="navbar-brand" href="index.html">RAPP Platform Web Services</a>
	</div>
	<div class="navbar-collapse">
		<ul class="nav navbar-nav">
			
			<li class="dropdown">
				<a href="global.html" class="dropdown-toggle" data-toggle="dropdown">Global<b class="caret"></b></a>
				<ul class="dropdown-menu ">
					<li><a href="global.html#available_services">available_services</a></li><li><a href="global.html#cognitive_test_chooser">cognitive_test_chooser</a></li><li><a href="global.html#face_detection">face_detection</a></li><li><a href="global.html#ontology_is_subsuperclass_of">ontology_is_subsuperclass_of</a></li><li><a href="global.html#ontology_subclasses_of">ontology_subclasses_of</a></li><li><a href="global.html#qr_detection">qr_detection</a></li><li><a href="global.html#record_cognitive_test_performance">record_cognitive_test_performance</a></li><li><a href="global.html#set_noise_profile">set_noise_profile</a></li><li><a href="global.html#speech_detecion_google">speech_detecion_google</a></li><li><a href="global.html#speech_detecion_sphinx4">speech_detecion_sphinx4</a></li><li><a href="global.html#text_to_speech">text_to_speech</a></li>
				</ul>
			</li>
			
		</ul>
	</div>
</div>
</div>


<div class="container">
<div class="row">

	
	<div class="col-md-8">
	
		<div id="main">
			

	
	











	
	





    <section class="readme-section">
        <article><h2>RAPP Platform Front-End Web Services</h2><h2>Synopsis</h2><p><strong>RAPP Platform Web Services</strong> are developed under the  <a href="https://github.com/manuel-serrano/hop">HOP web broker</a>.<br>These services are used in order to communicate with the RAPP Platform ecosystem and access RIC(RAPP Improvement Center) AI modules.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Platform Services</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">face_detection</td>
<td style="text-align:center">Performs face detection on given input image frame</td>
</tr>
<tr>
<td style="text-align:center">qr_detection</td>
<td style="text-align:center">Performs face detection on given input image frame</td>
</tr>
<tr>
<td style="text-align:center">text_to_speech</td>
<td style="text-align:center">Performs text-to-speech on given input plain text</td>
</tr>
<tr>
<td style="text-align:center">denoise_profile</td>
<td style="text-align:center">Used in order to perform given user's audio profile</td>
</tr>
<tr>
<td style="text-align:center">speech_detection_sphix4</td>
<td style="text-align:center">Performs speech-detection using the Platform integrated Sphinx4 engine</td>
</tr>
<tr>
<td style="text-align:center">speech_detection_google</td>
<td style="text-align:center">Performs speech-detection using the Platform integrated Google engine</td>
</tr>
<tr>
<td style="text-align:center">available_services</td>
<td style="text-align:center">Returns a list of the Platform available services (up-to-date)</td>
</tr>
<tr>
<td style="text-align:center">ontology_subclasses_of</td>
<td style="text-align:center">Perform Ontology, subclasses-of, query</td>
</tr>
<tr>
<td style="text-align:center">ontology_superclasses_of</td>
<td style="text-align:center">Perform Ontology, superclasses-of, query</td>
</tr>
<tr>
<td style="text-align:center">ontology_is_supsuperclass_of</td>
<td style="text-align:center">Perform Ontology, is-subsuperclass-of, query</td>
</tr>
<tr>
<td style="text-align:center">cognitive_test_chooser</td>
<td style="text-align:center">Returns a Cognitive Exercise literal that describes the test</td>
</tr>
<tr>
<td style="text-align:center">record_cognitive_test_performance</td>
<td style="text-align:center">Record user's performance on given Cognitive Exercise</td>
</tr>
</tbody>
</table>
<h2>Services</h2><h4>QR-Detection</h4><pre class="prettyprint source lang-javascript"><code>qr_detection ( {file_uri: ''} )</code></pre><h5>Input parameters</h5><ul>
<li>file_uri: Destination where the posted file data (<strong>image file</strong>) are saved by hop-server. Data are posted using a multipart/form-data post request using this field. e.g.</li>
</ul>
<pre class="prettyprint source lang-python"><code>file = {'file_uri': open(&lt;to-send-file-path>, 'rb')}</code></pre><h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ qr_centers: [], qr_messages: [], error: '' }</code></pre><ul>
<li>qr_centers: Vector that containes points (x,y) of found QR in an image frame.</li>
<li>qr_messages: Vector that containes message descriptions of found QR in an image frame.</li>
<li>error: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<p>Response Sample:</p>
<pre class="prettyprint source lang-javascript"><code>{
  qr_centers: [ { y: 165, x: 165 } ],
  qr_messages: ['rapp project qr sample'],
  error: ''
}</code></pre><h4>Face-Detection</h4><pre class="prettyprint source lang-javascript"><code>face_detection ( {file_uri: ''} )</code></pre><h5>Input parameters</h5><ul>
<li>file_uri: Destination where the posted file data (<strong>image file</strong>) are saved by hop-server. Data are posted using a multipart/form-data post request using this field. e.g.</li>
</ul>
<pre class="prettyprint source lang-python"><code>file = {'file_uri': open(&lt;to-send-file-path>, 'rb')}</code></pre><h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ faces: [{ up_left_point: {}, down_right_point: {} }], error: '' }</code></pre><p>Point coordinates are presented in Cartesian Coordinate System as:</p>
<pre class="prettyprint source lang-javascript"><code>{x: &lt;value_int>, y: &lt;value_int>}</code></pre><ul>
<li>faces: Dynamic vector that contains recognized faces in an image frame.</li>
<li>up_left_point: This Object literal contains the up-left point coordinates of detected face.</li>
<li>up_left_point: This Object literal contains the down-right point coordinates of detected face.</li>
<li>error: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<p>Response Sample:</p>
<pre class="prettyprint source lang-javascript"><code> {
   faces: [{
     up_left_point: { y: 200, x: 212 },
     down_right_point: { y: 379, x: 391 }
   }],
   error: ''
 }</code></pre><h3>Speech Detection related services.</h3><hr>
<h4>Denoise Audio Profile</h4><pre class="prettyprint source lang-javascript"><code>set_denoise_profile ( {file_uri: '', audio_source: '', user: ''} )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'file_uri'</strong>: Destination where the posted file data (<strong>audio data file</strong>) are saved by hop-server. Data are posted using a multipart/form-data post request using this field. e.g.</li>
</ul>
<pre class="prettyprint source lang-python"><code>file = {'file_uri': open(&lt;to-send-file-path>, 'rb')}</code></pre><ul>
<li><strong>'audio_source'</strong>: A value that presents the <robot><em><encode></em><channels> information for the audio source data. e.g &quot;nao_wav_1_ch&quot;.</li>
<li><strong>'user'</strong>: User’s name. Used for per-user profile denoise configurations.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ error: '&lt;error_message>' }</code></pre><ul>
<li>error: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<pre class="prettyprint source lang-javascript"><code>{ error:&quot;RAPP Platform Failure!&quot; }</code></pre><h4>Speech-Detection-Sphinx4</h4><pre class="prettyprint source lang-javascript"><code>speech_detection_sphinx4 ( { file_uri: '', language: '', audio_source: '', words: [], sentences: [], grammar: [], user: ''})</code></pre><h5>Input parameters</h5><ul>
<li><strong>'file_uri'</strong>: Destination where the posted file data (<strong>audio data file</strong>) are saved by hop-server. Data are posted using a multipart/form-data post request using this field. e.g.</li>
</ul>
<pre class="prettyprint source lang-python"><code>file = {'file_uri': open(&lt;to-send-file-path>, 'rb')}</code></pre><ul>
<li><strong>'language'</strong>: Language to be used by the speech_detection_sphinx4 module. Currently valid language values are ‘gr’ for Greek and ‘en’ for English.</li>
<li><strong>'audio_source'</strong>: A value that presents the <robot><em><encode></em><channels> information for the audio source data. e.g &quot;nao_wav_1_ch&quot;.</li>
<li><strong>'words[]'</strong>: A vector that carries the words to search for into the voice-audio-source.</li>
<li><strong>'sentences[]'</strong>: The under consideration sentences.</li>
<li><strong>'grammar[]'</strong>: Grammars to use in speech recognition.</li>
<li><strong>'user'</strong>: User’s name. Used for per-user profile denoise configurations.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ words: [], error: '&lt;error_message>' }</code></pre><ul>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field and returned to the client.</li>
<li><strong>'words[]'</strong>: A vector that contains the &quot;words-found&quot;</li>
</ul>
<h4>Speech-Detection-Google</h4><pre class="prettyprint source lang-javascript"><code>speech_detection_sphinx4 ( { file_uri: '', audio_source: '',  user: '', language: ''} )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'file_uri'</strong>: Destination where the posted file data (<strong>audio data file</strong>) are saved by hop-server. Data are posted using a multipart/form-data post request using this field. e.g.</li>
</ul>
<pre class="prettyprint source lang-python"><code>file = {'file_uri': open(&lt;to-send-file-path>, 'rb')}</code></pre><ul>
<li><strong>'language'</strong>: Language to be used by the speech_detection_sphinx4 module. Currently valid language values are ‘gr’ for Greek and ‘en’ for English.</li>
<li><strong>'audio_source'</strong>: A value that presents the {robot}<em>{encode}</em>{channels} information for the audio source data. e.g &quot;nao_wav_1_ch&quot;.</li>
<li><strong>'user'</strong>: User’s name. Used for per-user profile denoise configurations.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode<br>the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ words: [], alternatives: [] error: '&lt;error_message>' }</code></pre><ul>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field and returned to the client.</li>
<li><strong>'words[]'</strong>: A vector that contains the &quot;words-found&quot; with highest confidence.</li>
<li><strong>'alternatives[[]]'</strong>: Alternative sentences. e.g. [['send', 'mail'], ['send', 'email'], ['set', 'mail']...]</li>
</ul>
<h3>Ontology related services.</h3><hr>
<p>The following Platform services give access to the Platform integrated Ontology system.</p>
<h4>Ontology-SubClasses-Of</h4><pre class="prettyprint source lang-javascript"><code>ontology_subclasses_of ( { query: ''} )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'query'</strong>: The query to the ontology database.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode<br>the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ results: [], error: '&lt;error_message>' }</code></pre><ul>
<li><strong>'results'</strong>: Query results returned from ontology database.</li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<pre class="prettyprint source lang-javascript"><code> { results: [ 'http://knowrob.org/kb/knowrob.owl#Oven',
   'http://knowrob.org/kb/knowrob.owl#MicrowaveOven',
   'http://knowrob.org/kb/knowrob.owl#RegularOven',
   'http://knowrob.org/kb/knowrob.owl#ToasterOven'],
   error: ''
}</code></pre><h4>Ontology-SuperClasses-Of</h4><pre class="prettyprint source lang-javascript"><code>ontology_superclasses_of ( { query: ''} )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'query'</strong>: The query to the ontology database.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ results: [], error: '&lt;error_message>' }</code></pre><ul>
<li><strong>'results'</strong>: Query results returned from ontology database.</li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<h4>Ontology-Is-SubSuperClass-Of</h4><pre class="prettyprint source lang-javascript"><code>ontology_is_subsuperclass_of ( { parent_class: '', child_class: '', recursive: false } )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'parent_class'</strong>: The parent class name.</li>
<li><strong>'child_class'</strong>: The child class name.</li>
<li><strong>'recursive'</strong>: Defines if a recursive procedure will be used (true/false).</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode<br>the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ result: Bool, error: '&lt;error_message>' }</code></pre><ul>
<li><strong>'result'</strong>: Success index on ontology-is-subsuperclass-of query.</li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field and returned to the client.</li>
</ul>
<h3>Text-To-Speech (tts) related services</h3><hr>
<h4>Text-To-Speech</h4><pre class="prettyprint source lang-javascript"><code>text_to_speech( { text: '', language: ''} )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'text'</strong>: Input text to translate to audio data.</li>
<li><strong>'language'</strong>: Language to be used for the TTS module. Valid values are currently <strong>el</strong> and <strong>en</strong></li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode<br>the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ payload: &lt;audio_data>, basename: &lt;audio_file_basename>, encoding: &lt;payload_encoding>, error: &lt;error_message> }</code></pre><ul>
<li><strong>'payload'</strong>: The audio data payload. Payload encoding is defined by the 'encoding' json field. Decode the payload audio data (client-side) using the codec value from the 'encoding' field.</li>
<li><strong>'encoding</strong>: Codec used to encode the audio data payload. Currently encoding of binary data is done using base64 codec. Ignore this field. May be used in future implementations.</li>
<li><strong>'basename'</strong>: A static basename for the audio data file, returned by the platform service. Ignore this field. May be usefull in future implementations.</li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field.</li>
</ul>
<h3>Cognitive Exercises related services</h3><hr>
<h4>Cognitive-Test-Selector</h4><pre class="prettyprint source lang-javascript"><code>cognitive_test_chooser( { user: '', test_type: '' } )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'user'</strong>: Username of client used to retrieve information from database. e.g &quot;klpanagi&quot;</li>
<li><strong>'test_type'</strong>: Cognitive Exercise test type. Can be one of ['ArithmeticCts', 'AwarenessCts', 'ReasoningCts']</li>
</ul>
<h5>Response/Return-Data</h5><p> The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode<br> the received data.</p>
<pre class="prettyprint source lang-javascript"><code> { questions: [], possib_ans: [], correct_ans: [], test_instance: '', test_type: '', test_subtype: '', error: '' }</code></pre><ul>
<li><strong>'questions'</strong>: The exercise set of questions.</li>
<li><strong>'possib_ans'</strong>:  The set of answers for each question. vector<vector<string>&gt;</li>
<li><strong>'correct_ans'</strong>: The set of correct answers for each question. vector<string></li>
<li><strong>'test_instance'</strong>: Returned test name. For example, 'ArithmeticCts_askw0Snwk'</li>
<li><strong>'test_type'</strong>: Cognitive exercise class/type. Documentation on Cognitive Exercise classes can be found <a href="https://github.com/rapp-project/rapp-platform/tree/CognitiveSystem/rapp_cognitive_exercise">here</a></li>
<li><strong>'test_subtype'</strong>: Cognitive exercise sub-type. Documentation on Subtypes can be found <a href="https://github.com/rapp-project/rapp-platform/tree/CognitiveSystem/rapp_cognitive_exercise">here</a></li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field.</li>
</ul>
<h4>Cognitive-Test-Selector</h4><pre class="prettyprint source lang-javascript"><code>record_cognitive_test_performance( { user: '', test_instance: '', score: 0 } )</code></pre><h5>Input parameters</h5><ul>
<li><strong>'user'</strong>: Username of client used to retrieve information from database. e.g &quot;klpanagi&quot;</li>
<li><strong>'test_instance'</strong>: Cognitive Exercise test instance. The full cognitive test entry name as reported by the <strong>cognitive_test_chooser()</strong>.</li>
<li><strong>'score'</strong>: User's performance score on given test entry.</li>
</ul>
<h5>Response/Return-Data</h5><p>The returned data are in <em>JSON</em> representation. A JSON.load() from client side must follow in order to decode the received data.</p>
<pre class="prettyprint source lang-javascript"><code>{ performance_entry: '', error: '' }</code></pre><ul>
<li><strong>'performace_entry'</strong>: User's cognitive test performance entry in ontology.</li>
<li><strong>'error'</strong>: If error was encountered, an error message is pushed in this field.</li>
</ul>
<h3>Health - RAPP Platform Status</h3><hr>
<p>For RAPP developers.</p>
<h4>Rapp-Platform-Status</h4><pre class="prettyprint source lang-javascript"><code>rapp_platform_status()</code></pre><p>Invoke this service from your favourite web browser:</p>
<pre class="prettyprint source lang-javascript"><code>&lt;rapp_platform_pub_ipaddr>/9001/hop/rapp_platform_status</code></pre><h2>Tests</h2><p>Developed tests and testing tools are currently located under the <a href="https://github.com/rapp-project/rapp-platform/tree/master/rapp_testing_tools">rapp_testing_tools</a> package:</p>
<pre class="prettyprint source lang-shell"><code>$ &lt;path_to_rapp_platform_repo>/rapp_testing_tools/</code></pre><h2>Contributors</h2><ul>
<li>Konstaninos Panayiotou, [klpanagi@gmail.com]</li>
<li>Manos Tsardoulias, [etsardou@gmail.com]</li>
<li>Vincent Prunet, [vincent.prunet@inria.fr]</li>
</ul></article>
    </section>







		</div>
	</div>

	<div class="clearfix"></div>

	
		<div class="col-md-3">
			<div id="toc" class="col-md-3"></div>
		</div>
	

</div>
</div>


<footer>


	<span class="copyright">
	Rapp Project EU 2015
	</span>

<span class="jsdoc-message">
	Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.4.0</a>
	on Mon Dec 7th 2015 using the <a
	href="https://github.com/docstrap/docstrap">DocStrap template</a>.
</span>
</footer>

<!--<script src="scripts/sunlight.js"></script>-->
<script src="scripts/docstrap.lib.js"></script>
<script src="scripts/bootstrap-dropdown.js"></script>
<script src="scripts/toc.js"></script>

<script>
$( function () {
	$( "[id*='$']" ).each( function () {
		var $this = $( this );

		$this.attr( "id", $this.attr( "id" ).replace( "$", "__" ) );
	} );

	$( ".tutorial-section pre, .readme-section pre" ).each( function () {
		var $this = $( this );

		var example = $this.find( "code" );
		exampleText = example.html();
		var lang = /{@lang (.*?)}/.exec( exampleText );
		if ( lang && lang[1] ) {
			exampleText = exampleText.replace( lang[0], "" );
			example.html( exampleText );
			lang = lang[1];
		} else {
			lang = "javascript";
		}

		if ( lang ) {

			$this
			.addClass( "sunlight-highlight-" + lang )
			.addClass( "linenums" )
			.html( example.html() );

		}
	} );

	Sunlight.highlightAll( {
		lineNumbers : true,
		showMenu : true,
		enableDoclinks : true
	} );

	$( "#toc" ).toc( {
		anchorName  : function ( i, heading, prefix ) {
			var id = $( heading ).attr( "id" );
			return id && id.replace(/\~/g, '-inner-').replace(/\./g, '-static-') || ( prefix + i );
		},
		selectors   : "h1,h2,h3,h4",
		showAndHide : false,
                navbarOffset: 10,
		smoothScrolling: true
	} );

	$( "#toc>ul" ).addClass( "nav nav-pills nav-stacked" );
	$( "#main span[id^='toc']" ).addClass( "toc-shim" );
	$( '.dropdown-toggle' ).dropdown();
	//			$( ".tutorial-section pre, .readme-section pre" ).addClass( "sunlight-highlight-javascript" ).addClass( "linenums" );


} );
</script>



<!--Navigation and Symbol Display-->


<!--Google Analytics-->


</body>
</html>